#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# In[9]:


import gzip
#checking to make sure the data files are correct
with gzip.open("goodreads_books.json.gz", 'r') as f:
    line = f.readline()


# In[10]:


line


# In[11]:


import json
#reading in input data as a json file
json.loads(line)


# In[12]:


#formats the data into a more appealing chart
def parse_fields(line):
    data = json.loads(line)
    return{
        "book_id" : data["book_id"],
        "title" : data["title_without_series"],
        "ratings": data["ratings_count"],
        "url": data["url"],
        "cover_image": data["image_url"]
        
    }


# In[13]:


books_titles = []
with gzip.open("goodreads_books.json.gz",'r') as f:
    while True:
        line = f.readline()
        if not line:
            break
        fields = parse_fields(line)
        #runs through the data file and if it has less then 15 ratings move to
        #the next line
        try:
            ratings = int(fields["ratings"])
        except ValueError:
            continue
        if ratings > 15:
            books_titles.append(fields)


# In[14]:


#using pandas to import the dataframe datastructure
import pandas as pd
titles = pd.DataFrame.from_dict(books_titles)


# In[15]:


titles["ratings"] = pd.to_numeric(titles["ratings"]) 
#all the ratings were previously read in as strings changes those to numeric vals


# In[16]:


titles["mod_title"] = titles["title"].str.replace("[^a-zA-Z0-9 ]", "", regex=True)
#changes all titles to remove non alphanumeric values


# In[17]:


titles


# In[18]:


titles["mod_title"] = titles["mod_title"].str.lower() 
#sets all titles to lowercase


# In[19]:


titles["mod_title"] = titles["mod_title"].str.replace("\s+"," ", regex = True)
#gets rid of multiple spaces


# In[20]:


titles


# In[21]:


titles = titles[titles["mod_title"].str.len()>0]
#empty titles get removed


# In[22]:


titles.to_json("books_titles.json")
#dumps new data back in json file


# In[23]:


titles


# In[24]:


#Inverse Document Frequency Make Infrequent words more impactful (common in search queries)
#Example
#                  potter harry the
#______________________________
#The|              log(3/1) log(3/2) log(3/3)
#Harry The Potter| log(3/1) log(3/2) log(3/3)
#The Harry|        log(3/1) log(3/2) log(3/3)
#So based on the titles if you were searching for 'Harry Potter' the 2nd title would be at the top of the search query
#Implemented using sklearn 
from sklearn.feature_extraction.text import TfidfVectorizer
#this vectorizer does basically exactly that
vectorizer = TfidfVectorizer()
#use our mod titles in the vectorizer
tfidf = vectorizer.fit_transform(titles["mod_title"])


# In[25]:


#all of this is used to for the search query

from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re
#html to make the url a clickable link 
def make_clickable(val):
    return '<a target="_blank" href="{}">Goodreads</a>'.format(val, val)
#html in order to improve visual quality of the search results
def show_image(val):
    return '<a href="{}"><img src="{}" width=50></img></a>'.format(val, val)

def search(query,vectorizer):
    #same thing as earlier getting rid of all non alfanumeric characters and lower casing the values
    processed = re.sub("[^a-zA-Z0-9 ]", "", query.lower())
    query_vec = vectorizer.transform([query])
    similarity = cosine_similarity(query_vec, tfidf).flatten()#function that actually searces the matrix (how similar each row is)
    indices = np.argpartition(similarity, -10)[-10:] #gets the top 10 results
    results = titles.iloc[indices]
    #takes the rows with the HIGHEST number of ratings
    results = results.sort_values("ratings", ascending=False)
    #takes the top 5 and styles it
    return results.head(5).style.format({'url': make_clickable, 'cover_image': show_image})


# In[31]:


#find books that have a similar name and also gives out an id for the user to use
search("Dantes inferno",vectorizer)


# In[87]:


liked_books = ["703663","197710","34373"]


# In[ ]:




